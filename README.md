# Human Action Recognition in Videos using Keras (CNN + LSTM)

## Description:
This project implements a Human Action Recognition system using deep learning. The model combines Convolutional Neural Networks (CNN) for feature extraction and Long Short-Term Memory (LSTM) for temporal sequence processing. It is designed to classify human actions from videos with high accuracy.

## Requirements:
- Python 3.x
- TensorFlow 2.x
- Keras
- NumPy
- OpenCV
- Matplotlib

## Installation:
1. Clone the repository:
   git clone https://github.com/username/Human-Action-Recognition.git

2. Navigate to the project directory:
   cd Human-Action-Recognition

3. Install the dependencies:
   pip install -r requirements.txt

## Dataset:
The project uses a video dataset for human action recognition. You can either upload your own dataset to Google Drive or use publicly available datasets such as UCF101 or Kinetics. For ease of access, the dataset can be linked via Google Drive.

## How to Run:
1. Open the `action_recognition.ipynb` notebook in Google Colab or Jupyter Notebook.
2. Upload your dataset or link it from Google Drive.
3. Run all the cells to train the model and evaluate its performance.

## Results:
The model achieves an accuracy of approximately 95% for human action recognition on the UCF101 dataset. Performance may vary depending on the dataset used.

## License:
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgements:
- UCF101 dataset for human action recognition.
- TensorFlow and Keras documentation for model implementation.
